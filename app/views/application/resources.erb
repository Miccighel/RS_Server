<!DOCTYPE html>
<html lang="en">
<%= render partial: 'shared/assets' %>
<body class="bg-gray-dark color-white">
<div class="min-h-100 d-flex flex-column align-items-center justify-content-center">
	<div class="w-100 mb-3">
		<%= render partial: 'shared/menu', locals: {active: "about", appearance: "light"} %>
	</div>
	<div class="row w-100 m-auto">
		<div class="col-12">
			<div class="heading text-center">
				<h1>Readersourcing </h1>
			</div>
		</div>
		<div class="col-12 mb-3">
			<div class="col-lg-6 col-sm-10 col-xs-12 m-auto">
				<p class="lead text-justify mb-1">
					This ecosystem is mainly conceived and built upon the concept of
					<strong><a class="link-white" href="http://en.wikipedia.org/wiki/Crowdsourcing">Crowdsourcing</a></strong>, a
					neologism coined by Jeff Howe in 2006 and currently described in Wikipedia as
					<i>the process in which a task traditionally performed by an employee or contractor"
						is outsourced to an undefined, generally large group of people or community in the form of an open call</i>.
					In particular, the term <i>Readersourcing</i>refers to a specific instantiation of such concept. <br/>The final purpose of this ecosystem is to have readers of
					scholarly papers that also participate in the
					rating process of the content they read. There are several rationales for this approach. One of them is to overcome the always more frequent shortage of
					available competent referees, mainly caused by the increased rate at which scientific articles are written and submitted for
					review nowadays, without being actually paired by an equally significant growth rate of referees. Modern technologies and globalization have in fact provided
					several advantages to scientific writing, but they do not help the peer reviewing process to the same extent, finally unbalancing the existing equilibrium
					between scientific writers and reviewers. Another good reason is to exploit, for free, the opinions that readers of a scholarly paper do have after having read
					it: currently, these opinions are often wasted and forgotten, or spread in a very informal and not effective way. <br/>
					The <strong>Readersourcing</strong> model aims at taking advantage of reader opinions, in order to overcome referees shortage, and also to follow the mass
					collaboration, collective intelligence, and wisdom of the crowd principles enabled and enhanced by Web 2.0. Of course, simply allowing readers to express their
					judgement on the paper they read cannot be a reasonable approach, as not all readers can be considered equally prepared and reliable; that is why the proposed
					model also
					assigns a rating to each reviewer, so that judgments from those who have proven to be good reviewers do count more than those who should not be trusted. Such a
					rating is implicitly and dynamically generated by the system, through the continuous comparison of the judgments expressed by the readers on each paper with its
					current score; providing - or having provided - correct (wrong) judgments will therefore lead to higher (lower) reader ratings, hopefully generating a virtuous
					circle.
				</p>
			</div>
		</div>
		<div class="col-12">
			<div class="heading text-center">
				<h1>Additional Details</h1>
			</div>
		</div>
		<div class="col-12 mb-3">
			<div class="col-lg-6 col-sm-10 col-xs-12 m-auto">
				<p class="lead text-justify mb-1">
					This ecosystem has been recently presented during the <strong>IRCDL 2019 Conference</strong>. The original paper can be found on <strong>Zenodo</strong>, while
					the code and the related
					documentation is
					available on <strong>GitHub</strong>. Take advantage of the badges below to exploit these resources.
				</p>
				<p class="text-center">
					<a href="https://ircdl2019.isti.cnr.it/" target="_blank"><img src="https://img.shields.io/badge/IRCDL%202019-Conference-yellow.svg"></a>
					<a href="https://doi.org/10.5281/zenodo.1446468" target="_blank"><img src="https://img.shields.io/badge/Zenodo-Paper-blue.svg"></a>
					<a href="https://github.com/Miccighel/Readersourcing-2.0" target="_blank"><img src="https://img.shields.io/badge/GitHub-Code-lightgrey.svg"></a>
				</p>
			</div>
		</div>
		<div class="col-12">
			<div class="heading text-center">
				<h1>References</h1>
			</div>
		</div>
		<div class="col-12">
			<div class="col-lg-6 col-sm-10 col-xs-12 m-auto">
				<ul>
					<li>
						<p class="lead text-justify mb-1">
							Soprano M., Mizzaro S. (2019) Crowdsourcing Peer Review: As We May Do. In: Manghi P.,
							Candela L., Silvello G. (eds) Digital Libraries: Supporting Open Science. IRCDL 2019.
							Communications in Computer and Information Science, vol 988. Springer, Cham,
							<a class="link-white" href="https://doi.org/10.1007%2F978-3-030-11226-4_21">doi:10.1007/978-3-030-11226-4_21</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Mizzaro, S.: Quality control in scholarly publishing: A new proposal. JA-SIST 54(11), 989--1005 (2003),
							<a class="link-white" href="https://doi.org/10.1002/asi.10296">doi:10.1002/asi.10296</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Mizzaro, S.: Readersourcing - A Manifesto. JASIST 63(8), 1666--1672 (2012),
							<a class="link-white" href="https://doi.org/10.1002/asi.2266">doi:10.1002/asi.2266</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							CC Attribution 4.0 International Public License (2010),
							<a class="link-white" href="https://creativecommons.org/licenses/by/4.0/legalcode">creativecommons.org/licenses/by/4.0/legalcode</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							OpenReview (2016), <a class="link-white" href="https://openreview.net/">openreview.net/</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Akst, J.: I Hate Your Paper: Many say the peer review system is broken. Here's how some journals are trying to x it. The Scientist 24, 36 (08 2010),
							<a class="link-white" href="http://www.the-scientist.com/2010/8/1/36/1/">the-scientist.com/2010/8/1/36/1/</a>.
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Arms, W.Y.: What are the alternatives to peer review? quality control in scholarly publishing on the web. JEP 8(1) (2002)
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							De Alfaro, L., Faella, M.: TrueReview: A Platform for Post-Publication Peer Review. CoRR (2016),
							<a class="link-white" href="http://arxiv.org/abs/1608.07878">arxiv.org/abs/1608.07878</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Dow, S., Kulkarni, A., Klemmer, S., Hartmann, B.: Shepherding the crowd yields better work. In: Proceedings of ACM 2012 CSCW. pp. 1013{1022. ACM (2012)
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Medo, M., RushtonWakeling, J.: The eect of discrete vs. continuous-valued ratings on reputation and ranking systems. EPL 91(4), 48004 (2010),
							<a class="link-white" href="http://stacks.iop.org/0295-5075/91/i=4/a=48004">stacks.iop.org/0295-5075/91/i=4/a=48004</a>
						</p>
					</li>
					<li>
						<p class="lead mb-1">
							Meyer, B.: Fixing the Process of Computer Science Refereeing (10 2010),
							<a class="link-white" href="https://cacm.acm.org/blogs/blog-cacm/100030-fixing-the-process-o
							f-computer-science-refereeing/fulltext">cacm.acm.org/blogs/blog-cacm/100030-fixing-the-process-o
								f-computer-science-refereeing/fulltext</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Mizzaro, S.: Quality control in scholarly publishing: A new proposal. JA-SIST 54(11), 989-1005 (2003),
							<a class="link-white" href="https://doi.org/10.1002/asi.22668">doi.org/10.1002/asi.22668</a>
						</p>
					</li>
					<li>
						<p class="lead mb-1">
							Mizzaro, S.: Readersourcing - A Manifesto. JA-SIST 63(8), 1666{1672 (2012),
							<a class="link-white" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.22668">onlinelibrary.wiley.com/doi/abs/10.1002/asi.22668</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Soprano, M., Mizzaro, S.: Readersourcing 2.0: RS_PDF,
							<a class="link-white" href="https://doi.org/10.5281/zenodo.1442597">doi.org/10.5281/zenodo.1442597</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Soprano, M., Mizzaro, S.: Readersourcing 2.0: RS_Rate,
							<a class="link-white" href="https://doi.org/10.5281/zenodo.1442599">doi.org/10.5281/zenodo.1442599</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Soprano, M., Mizzaro, S.: Readersourcing 2.0: RS_Server,
							<a class="link-white" href="https://doi.org/10.5281/zenodo.1442630">doi.org/10.5281/zenodo.1442630</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Soprano, M., Mizzaro, S.: Readersourcing 2.0: Technical Documentation,
							<a class="link-white" href="https://doi.org/10.5281/zenodo.1443371">doi.org/10.5281/zenodo.1443371</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Sun, Y., Cheng, P., Wang, S., Lyu, H., Lease, M., Marshall, I.J., Wallace, B.C.: Crowdsourcing Information Extraction for Biomedical Systematic Reviews. CoRR abs/1609.01017 (2016)
						</p>
					</li>
					<li>
						<p class="lead mb-1">
							The Economist: Some science journals that claim to peer review papers do not do so (2018),
							<a class="link-white" href="https://www.economist.com/science-and-technology/2018/06/23/some-science-journals-that-claim-to-peer-review-papers-do-n ot-do-so">
								economist.com/science-and-technology/2018/06/23/some-science-journals-that-claim-to-peer-review-papers-do-n ot-do-so
							</a>
						</p>
					</li>
					<li>
						<p class="lead text-justify mb-1">
							Tomkins, A., Zhang, M., Heavlin, W.D.: Reviewer bias in single-versus double-blind peer review. PNAS 114(48), 12708{12713 (2017),
							<a class="link-white" href="http://www.pnas.org/content/114/48/12708">pnas.org/content/114/48/12708</a>
						</p>
					</li>
				</ul>
			</div>
		</div>
	</div>
	<div class="row w-100 mt-3">
		<%= render partial: "shared/footer" %>
	</div>
</div>
</body>
</html>